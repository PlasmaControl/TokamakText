# bot.py
import os
import discord
from dotenv import load_dotenv
from rag import retrieve, rag_answer_question
from llm_interface import get_llm_interface

# Load the environment variables
load_dotenv()
TOKEN = os.getenv('DISCORD_TOKEN')

# Configure Discord intents
intents = discord.Intents.default()
intents.messages = True
intents.message_content = True
intents.guilds = True

# Initialize Discord client
client = discord.Client(intents=intents)

# Get the large language model interface
model = get_llm_interface('openai')

@client.event
async def on_ready():
    """
    Event handler for when the Discord bot is ready and has successfully connected.
    Logs the connection status to the console.
    """
    print(f'{client.user} has connected to Discord!')

@client.event
async def on_message(message):
    """
    Event handler for when a message is received.

    Parameters
    ----------
    message : discord.Message
        The message object that contains the message details and content.

    Returns
    -------
    None
        This function returns None, but it sends a message to the channel with either the
        thinking process or the answer generated by the RAG model.
    """
    if message.author == client.user:
        return

    if client.user not in message.mentions:
        return

    question = message.content
    results = retrieve(question)
    retrieved_results = "\n".join([f"{key}: {value}" for key, value in results.items()])
    generated_answer = rag_answer_question(question, results, model)

    split_response = generated_answer.split("ANSWER:")
    thinking = split_response[0].strip()
    answer = split_response[1].strip() if len(split_response) > 1 else ""

    output = f"{thinking}\n\n{answer}"
    await message.channel.send(output)

client.run(TOKEN)